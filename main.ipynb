{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TNT hand gestures study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flow of program\n",
    "DELETE BEFORE SUBMISSION\n",
    "\n",
    "-   code to import data from 3 csv files held in the data folder\n",
    "-   data is then combined in a dictionary and then converted to a pandas dataframe\n",
    "-   the data is then cleaned and the columns are renamed\n",
    "-   the data is then split into a training and testing set\n",
    "-   a linear regression model is then fitted to the training data\n",
    "-   the model is then used to predict the test data\n",
    "-   the mean squared error and r2 score are then calculated\n",
    "-   the results are then printed to the console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing relevant libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-----------------Information-----------------#\n",
    "\n",
    "'''\n",
    "    Title: Linear Regression Model for Predicting Absolute Acceleration\n",
    "    Data Collection Declaration:\n",
    "\n",
    "    This project is being developed for a Data Science and Machine Learning class.\n",
    "    The data used in this project was collected by the student developers at the University of Nottingham. \n",
    "\n",
    "    Legal Aspects:\n",
    "\n",
    "    The data collection process complied with all applicable laws and university policies. \n",
    "    Any personal data that was collected has been anonymized to protect the privacy of the individuals involved. \n",
    "\n",
    "    Please note that the use of this data must comply with all relevant data protection and privacy laws. \n",
    "    Unauthorized use, disclosure, or duplication of this data is strictly prohibited.\n",
    "'''\n",
    "'''\n",
    "    Data Information:\n",
    "\n",
    "    Data within the dataset being examined is of the format of a csv file with the following columns:\n",
    "    Column Names and Types:\n",
    "    \n",
    "    '''\n",
    "\n",
    "#-----------------Information-----------------#\n",
    "\n",
    "#-----------------Importing Libraries-----------------#\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#-----------------Importing Libraries-----------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-----------------Flags-----------------#\n",
    "\n",
    "SYS_MSG = True # Flag to toggle control over printing system messages to console \n",
    "PLOT = True # Flag to toggle control over plotting graphs\n",
    "TEST_PLOT = False # Flag to toggle control over plotting test graphs\n",
    "\n",
    "#-----------------Flags-----------------#\n",
    "\n",
    "#-----------------Basic Functions-----------------#\n",
    "\n",
    "# Function to print system messages\n",
    "def print_sys_msg(msg):\n",
    "    if SYS_MSG:\n",
    "        print('-'*10+'System control message \\n'+msg)\n",
    "\n",
    "# Function to print normal messages\n",
    "def print_msg(msg):\n",
    "    print('-'*10+'Message \\n'+msg)\n",
    "\n",
    "#-----------------Basic Functions-----------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preperation Phase  \n",
    "We create base classes to manage our data, visualisation, analysis, and prediction.  \n",
    "Creating DataHandler class. It wwill manage the import, stored manipulation, and final storage of data.  \n",
    "\\- [member name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------DataHandler Class-----------------#\n",
    "'''\n",
    "Class DataHandler\n",
    "    purpose: import and manage data (data manipulation, data wrangling, and data preprocessing)\n",
    "\n",
    "    initialization example:\n",
    "        data = DataHandler()\n",
    "    \n",
    "    functions:\n",
    "    - import_data: import data from csv files and combine them into a single dataframe\n",
    "        dependencies used: pandas\n",
    "        function call example: data.import_data(['data/member1.csv', 'data/member2.csv', 'data/member3.csv'])\n",
    "        input: list of file names\n",
    "        output: none\n",
    "    \n",
    "    - import_data_system: import data from the system\n",
    "        dependencies used: pandas, os\n",
    "        function call example: data.import_data_system(['data/member1', 'data/member2', 'data/member3'])\n",
    "        input: list of directory names\n",
    "        output: none\n",
    "        \n",
    "    - data_shape: print the shape of the dataframe\n",
    "        dependencies used: pandas\n",
    "        function call example: data.data_shape()\n",
    "        input: none\n",
    "        output: none\n",
    "\n",
    "    - data_head: print the first 5 rows of the dataframe\n",
    "        dependencies used: pandas\n",
    "        function call example: data.data_head()\n",
    "        input: none\n",
    "        output: none\n",
    "\n",
    "    - data_info: print the information of the dataframe\n",
    "        dependencies used: pandas\n",
    "        function call example: data.data_info()\n",
    "        input: none\n",
    "        output: none\n",
    "\n",
    "    - data_describe: print the description of the dataframe\n",
    "        dependencies used: pandas\n",
    "        function call example: data.data_describe()\n",
    "        input: none\n",
    "        output: none\n",
    "\n",
    "    - data_null: print the null values in the dataframe\n",
    "        dependencies used: pandas\n",
    "        function call example: data.data_null()\n",
    "        input: none\n",
    "        output: none\n",
    "    \n",
    "    - data_corr: print the correlation matrix of the dataframe\n",
    "        dependencies used: pandas\n",
    "        function call example: data.data_corr()\n",
    "        input: none\n",
    "        output: none\n",
    "\n",
    "    - drop_duplicates: drop duplicates        \n",
    "        dependencies used: pandas\n",
    "        function call example: data.drop_duplicates()\n",
    "        input: none\n",
    "        output: none\n",
    "\n",
    "    - drop_null: drop null values     \n",
    "        dependencies used: pandas\n",
    "        function call example: data.drop_null()\n",
    "        input: none\n",
    "        output: none\n",
    "    \n",
    "    - drop_outliers: drop outliers\n",
    "        dependencies used: pandas\n",
    "        function call example: data.drop_outliers()\n",
    "        input: none\n",
    "        output: none\n",
    "\n",
    "    - drop_negative_time: drop negative time values\n",
    "        dependencies used: pandas\n",
    "        function call example: data.drop_negative_time()\n",
    "        input: none\n",
    "        output: none\n",
    "        \n",
    "- Managed by: Samarth\n",
    "- Created on: 03/02/2024\n",
    "- Modified on: 03/02/2024\n",
    "- Contact:  psxs2@nottingham.ac.uk\n",
    "'''\n",
    "class DataHandler:\n",
    "    data = None\n",
    "    df = None\n",
    "\n",
    "    #-----------------Data Import Functions-----------------#\n",
    "    \n",
    "    # declaration example - data = DataHandler.import_data(['data/member1.csv', 'data/member2.csv', 'data/member3.csv'])\n",
    "    def import_data(self, files):\n",
    "            print_sys_msg('DataHandler:import_data: importing data from 3 csv files and combining them into a single dataframe')\n",
    "            number_of_files = len(files)\n",
    "            for i in range(number_of_files):\n",
    "                if i == 0:\n",
    "                    self.df = pd.read_csv(files[i])\n",
    "                    self.data = {'data_'+str(i+1): pd.read_csv(files[i])}\n",
    "                else:\n",
    "                    self.df = pd.concat([self.df, pd.read_csv(files[i])], ignore_index=True)\n",
    "                    self.data['data_'+str(i+1)] = pd.read_csv(files[i])\n",
    "            print_sys_msg('DataHandler:import_data: data imported successfully')\n",
    "\n",
    "    # declaration example - data = DataHandler.import_data_system(['data/member1', 'data/member2', 'data/member3'])\n",
    "    def import_data_system(self, directorys):\n",
    "        print_sys_msg('DataHandler:import_data: importing data from the system')\n",
    "        \n",
    "        # all files are imported for each directory listed in the directories list\n",
    "        # the data is then combined into a single dataframe\n",
    "        # the data is stored in a dictionary with the directory name as the key\n",
    "\n",
    "        for directory in directorys:\n",
    "            files = os.listdir(directory)\n",
    "            number_of_files = len(files)\n",
    "            for i in range(number_of_files):\n",
    "                if i == 0:\n",
    "                    self.df = pd.read_csv(directory+'/'+files[i])\n",
    "                    self.data = {'data_'+str(i+1): pd.read_csv(directory+'/'+files[i])}\n",
    "                else:\n",
    "                    self.df = pd.concat([self.df, pd.read_csv(directory+'/'+files[i])], ignore_index=True)\n",
    "                    self.data['data_'+str(i+1)] = pd.read_csv(directory+'/'+files[i])\n",
    "\n",
    "    #-----------------Data Import Functions-----------------#\n",
    "    #-----------------Basic Data Wrangling Functions-----------------#\n",
    "    \n",
    "    def data_shape(self):\n",
    "        print_sys_msg('DataHandler:data_shape: printing the shape of the dataframe')\n",
    "        print_sys_msg(str(self.df.shape))\n",
    "    def data_head(self):\n",
    "        print_sys_msg('DataHandler:data_head: printing the first 5 rows of the dataframe')\n",
    "        print_sys_msg(str(self.df.head()))\n",
    "    \n",
    "    def data_info(self):\n",
    "        print_sys_msg('DataHandler:data_info: printing the information of the dataframe')\n",
    "        print_sys_msg(str(self.df.info()))\n",
    "                      \n",
    "    def data_describe(self):\n",
    "        print_sys_msg('DataHandler:data_describe: printing the description of the dataframe')\n",
    "        print_sys_msg(str(self.df.describe()))\n",
    "                      \n",
    "    def data_null(self):\n",
    "        print_sys_msg('DataHandler:data_null: printing the null values in the dataframe')\n",
    "        print_sys_msg(str(self.df.isnull().sum()))\n",
    "                      \n",
    "    def data_corr(self):\n",
    "        print_sys_msg('DataHandler:data_corr: printing the correlation matrix of the dataframe')\n",
    "        print_sys_msg(str(self.df.corr()))\n",
    "    \n",
    "    def data_missing(self):\n",
    "        print_sys_msg('DataHandler:data_missing: printing the missing values in the dataframe')\n",
    "        print_sys_msg(str(self.df.isna().any(axis=1)))\n",
    "    #-----------------Basic Data Wrangling Functions-----------------#\n",
    "        \n",
    "    #-----------------Data Preprocessing Functions-----------------#\n",
    "\n",
    "    def drop_duplicates(self):\n",
    "        print_sys_msg('DataHandler:drop_duplicates: dropping duplicates')\n",
    "        self.df = self.df.drop_duplicates()\n",
    "    \n",
    "    def drop_null(self):\n",
    "        print_sys_msg('DataHandler:drop_null: dropping null values')\n",
    "        self.df = self.df.dropna()\n",
    "\n",
    "\n",
    "    # def drop_outliers(self):\n",
    "    #     print_sys_msg('DataHandler:drop_outliers: dropping outliers'\n",
    "    #     self.df = self.df[(self.df['Linear Acceleration x (m/s^2)'] > -10) & (self.df['Linear Acceleration x (m/s^2)'] < 10)]\n",
    "    #     self.df = self.df[(self.df['Linear Acceleration y (m/s^2)'] > -10) & (self.df['Linear Acceleration y (m/s^2)'] < 10)]\n",
    "    #     self.df = self.df[(self.df['Linear Acceleration z (m/s^2)'] > -10) & (self.df['Linear Acceleration z (m/s^2)'] < 10)]\n",
    "    #     self.df = self.df[(self.df['Absolute acceleration (m/s^2)'] > 0) & (self.df['Absolute acceleration (m/s^2)'] < 10)]\n",
    "\n",
    "    def drop_negative_time(self):\n",
    "        print_sys_msg('DataHandler:drop_negative_time: dropping negative time values')\n",
    "        self.df = self.df[self.df['Time (s)'] > 0]\n",
    "\n",
    "    # missing values handling - drop rows with missing values\n",
    "    def drop_missing(self, threshold=3):\n",
    "        print_sys_msg('DataHandler:drop_missing: dropping missing values')\n",
    "        self.df = self.df.dropna(thresh=threshold).copy()\n",
    "\n",
    "    # missing values handling - fill missing values with mean of the column\n",
    "    def fill_missing(self):\n",
    "        print_sys_msg('DataHandler:fill_missing: filling missing values with mean of the column')\n",
    "        self.df = self.df.fillna(self.df.mean())\n",
    "\n",
    "    # missing values handling - fill missing values with median of the column\n",
    "    def fill_missing_median(self):\n",
    "        print_sys_msg('DataHandler:fill_missing_median: filling missing values with median of the column')\n",
    "        self.df = self.df.fillna(self.df.median())\n",
    "    \n",
    "    # missing values handling - fill missing values with mode of the column\n",
    "    def fill_missing_mode(self):\n",
    "        print_sys_msg('DataHandler:fill_missing_mode: filling missing values with mode of the column')\n",
    "        self.df = self.df.fillna(self.df.mode().iloc[0])\n",
    "    \n",
    "    # missing values handling - fill missing values with bill debth of the column\n",
    "    #-----------------------------------\n",
    "    #-----------------------------------To be written\n",
    "    #-----------------------------------\n",
    "    \n",
    "    # data normalization - min-max normalization\n",
    "    def min_max_normalization(self):\n",
    "        print_sys_msg('DataHandler:min_max_normalization: min-max normalization')\n",
    "        self.df = (self.df - self.df.min()) / (self.df.max() - self.df.min())\n",
    "    \n",
    "    # data normalization - standardization\n",
    "    def standardization(self):\n",
    "        print_sys_msg('DataHandler:standardization: standardization')\n",
    "        self.df = (self.df - self.df.mean()) / self.df.std()\n",
    "    \n",
    "\n",
    "    #-----------------Data Preprocessing Functions-----------------#\n",
    "\n",
    "\n",
    "    #-----------------Data Splitting Functions-----------------#\n",
    "    \n",
    "    #-----------------Data Splitting Functions-----------------#\n",
    "        \n",
    "    #-----------------Storing Data Functions-----------------#\n",
    "\n",
    "    def store_data_with_name(self, file_name):\n",
    "        print_sys_msg('DataHandler:store_data: storing data to a csv file')\n",
    "        self.df.to_csv(file_name, index=False)\n",
    "    \n",
    "    def store_data_with_current_date_time(self):\n",
    "        print_sys_msg('DataHandler:store_data_with_current_date_time: storing data to a csv file with current date and time')\n",
    "        self.df.to_csv('data_'+str(pd.to_datetime('today'))+'.csv', index=False)\n",
    "    \n",
    "    def store_data_with_index(self):\n",
    "        print_sys_msg('DataHandler:store_data_with_index: storing data to a csv file with index')\n",
    "        \n",
    "        # data is stored with index only\n",
    "        # getting the highest index of the data in the data folder and then incrementing it by 1\n",
    "        # storing the data with the new index\n",
    "        #-----------------------------------\n",
    "        #-----------------------------------To be written\n",
    "\n",
    "    #-----------------Storing Data Functions-----------------#\n",
    "\n",
    "#-----------------DataHandler Class-----------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we make a basic visualization class that will manage the plotting and core visualization functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------DataVisualization Class-----------------#\n",
    "'''\n",
    "Class DataVisualization\n",
    "\n",
    "    purpose: visualize data (data visualization)\n",
    "    charts included: line, scatter, bar, histogram, box plot, violin plot, bullet, table, sparkline, connected scatter plot, box, pie, doughnut, gauge, waffle\n",
    "    \n",
    "    functions:\n",
    "    -   plt_create_linear_sub_plots: create linear sub plots\n",
    "        dependencies used: matplotlib\n",
    "        function call example: DataVisualization(DataHandler).plt_create_linear_sub_plots('left_to_right', [['line', 'Time (s)', 'Absolute acceleration (m/s^2)'], ['scatter', 'Time (s)', 'Absolute acceleration (m/s^2)']])\n",
    "        input: arrangement type (arrangment), list of plots (plot_list)\n",
    "        output: none\n",
    "\n",
    "    -   plt_create_grid_sub_plots: create grid sub plots\n",
    "        dependencies used: matplotlib, math\n",
    "        function call example: DataVisualization(DataHandler).plt_create_grid_sub_plots([['line', 'Time (s)', 'Absolute acceleration (m/s^2)'], ['scatter', 'Time (s)', 'Absolute acceleration (m/s^2)']])\n",
    "        input: list of plots (plot_list)\n",
    "        output: none\n",
    "\n",
    "    -   sns_create_linear_sub_plots: create linear sub plots\n",
    "        dependencies used: seaborn\n",
    "        function call example: DataVisualization(DataHandler).sns_create_linear_sub_plots('left_to_right', [['line', 'Time (s)', 'Absolute acceleration (m/s^2)'], ['scatter', 'Time (s)', 'Absolute acceleration (m/s^2)']])\n",
    "        input: arrangement type (arrangment), list of plots (plot_list)\n",
    "        output: none\n",
    "\n",
    "    -   sns_create_grid_sub_plots: create grid sub plots\n",
    "        dependencies used: seaborn, math\n",
    "        function call example: DataVisualization(DataHandler).sns_create_grid_sub_plots([['line', 'Time (s)', 'Absolute acceleration (m/s^2)'], ['scatter', 'Time (s)', 'Absolute acceleration (m/s^2)']])\n",
    "        input: list of plots (plot_list)\n",
    "        output: none\n",
    "    \n",
    "- Managed by: \n",
    "- Created on: 03/02/2024\n",
    "- Modified on: 03/02/2024\n",
    "- Contact: @nottingham.ac.uk\n",
    "'''\n",
    "\n",
    "class DataVisualization:\n",
    "    DataHandler = None\n",
    "    def __init__(self, DataHandler):\n",
    "        self.DataHandler = DataHandler\n",
    "    \n",
    "    #-----------------matplot based Base Data Visualization Functions-----------------#\n",
    "\n",
    "    # declaration example - DataVisualization(DataHandler).create_sub_plots('left_to_right', [['line', 'Time (s)', 'Absolute acceleration (m/s^2)'], ['scatter', 'Time (s)', 'Absolute acceleration (m/s^2)']])\n",
    "    def plt_create_linear_sub_plots(self, arrangment ,plot_list):\n",
    "        print_sys_msg('DataVisualization:create_base_plots: creating base plots')\n",
    "        number_of_plots = len(plot_list)\n",
    "\n",
    "        if arrangment == 'left_to_right':\n",
    "            fig, ax = plt.subplots(1, number_of_plots, figsize=(20, 20))\n",
    "        elif arrangment == 'top_to_bottom':\n",
    "            fig, ax = plt.subplots(number_of_plots, 1, figsize=(20, 20))  \n",
    "        else:\n",
    "            print_sys_msg('DataVisualization:create_base_plots: invalid arrangement type') \n",
    "            return    \n",
    "        \n",
    "        for i in range(number_of_plots):\n",
    "            if len(plot_list[i]) >= 3:\n",
    "                # plotting line graph\n",
    "                if plot_list[i][0] == 'line':\n",
    "                    ax[i].plot(self.DataHandler.df[plot_list[i][1]], self.DataHandler.df[plot_list[i][2]])\n",
    "                # plotting scatter graph\n",
    "                elif plot_list[i][0] == 'scatter':\n",
    "                    ax[i].scatter(self.DataHandler.df[plot_list[i][1]], self.DataHandler.df[plot_list[i][2]])\n",
    "                # plotting bar graph\n",
    "                elif plot_list[i][0] == 'bar':\n",
    "                    ax[i].bar(self.DataHandler.df[plot_list[i][1]], self.DataHandler.df[plot_list[i][2]])\n",
    "                # plotting histogram\n",
    "                elif plot_list[i][0] == 'hist':\n",
    "                    ax[i].hist(self.DataHandler.df[plot_list[i][1]], bins=10)\n",
    "                # plotting box plot\n",
    "                elif plot_list[i][0] == 'box':\n",
    "                    ax[i].boxplot(self.DataHandler.df[plot_list[i][1]])\n",
    "                # plotting violin plot\n",
    "                elif plot_list[i][0] == 'violin':\n",
    "                    ax[i].violinplot(self.DataHandler.df[plot_list[i][1]])\n",
    "                elif plot_list[i][0] == 'bullet':\n",
    "                    ax[i].bullet(self.DataHandler.df[plot_list[i][1]])\n",
    "                elif plot_list[i][0] == 'table':\n",
    "                    ax[i].table(self.DataHandler.df[plot_list[i][1]])\n",
    "                elif plot_list[i][0] == 'sparkline':\n",
    "                    ax[i].sparkline(self.DataHandler.df[plot_list[i][1]])\n",
    "                elif plot_list[i][0] == 'connected scatter plot':\n",
    "                    ax[i].connectedscatterplot(self.DataHandler.df[plot_list[i][1]])\n",
    "                elif plot_list[i][0] == 'pie':\n",
    "                    ax[i].pie(self.DataHandler.df[plot_list[i][1]])\n",
    "                elif plot_list[i][0] == 'doughnut':\n",
    "                    ax[i].doughnut(self.DataHandler.df[plot_list[i][1]])\n",
    "                elif plot_list[i][0] == 'gauge':\n",
    "                    ax[i].gauge(self.DataHandler.df[plot_list[i][1]])\n",
    "                elif plot_list[i][0] == 'waffle':\n",
    "                    ax[i].waffle(self.DataHandler.df[plot_list[i][1]])\n",
    "                # invalid plot type\n",
    "                else:\n",
    "                    print_sys_msg('DataVisualization:create_base_plots: invalid plot type')\n",
    "                \n",
    "                ax[i].set_xlabel(plot_list[i][1])\n",
    "                ax[i].set_ylabel(plot_list[i][2])\n",
    "                ax[i].set_title(plot_list[i][1]+' vs '+plot_list[i][2])\n",
    "                                                                                \n",
    "        plt.show()\n",
    "    \n",
    "    def plt_create_grid_sub_plots(self, plot_list):\n",
    "        print_sys_msg('DataVisualization:create_base_plots: creating base plots')\n",
    "\n",
    "        number_of_plots = len(plot_list)\n",
    "        print_sys_msg('DataVisualization:create_base_plots: number_of_plots: '+str(number_of_plots))\n",
    "        temp = math.ceil(math.sqrt(number_of_plots))\n",
    "        print_sys_msg('DataVisualization:create_base_plots: temp: '+str(temp))\n",
    "        fig, ax = plt.subplots(temp, temp, figsize=(20, 20))\n",
    "\n",
    "        for i in range(temp):\n",
    "            for j in range(temp):\n",
    "                if (i*temp+j) < number_of_plots:\n",
    "                    if len(plot_list[i*temp+j]) >= 3:\n",
    "                        # plotting line graph\n",
    "                        if plot_list[i*temp+j][0] == 'line':\n",
    "                            ax[i, j].plot(self.DataHandler.df[plot_list[i*temp+j][1]], self.DataHandler.df[plot_list[i*temp+j][2]])\n",
    "                        # plotting scatter graph\n",
    "                        elif plot_list[i*temp+j][0] == 'scatter':\n",
    "                            ax[i, j].scatter(self.DataHandler.df[plot_list[i*temp+j][1]], self.DataHandler.df[plot_list[i*temp+j][2]])\n",
    "                        # plotting bar graph\n",
    "                        elif plot_list[i*temp+j][0] == 'bar':\n",
    "                            ax[i, j].bar(self.DataHandler.df[plot_list[i*temp+j][1]], self.DataHandler.df[plot_list[i*temp+j][2]])\n",
    "                        # plotting histogram\n",
    "                        elif plot_list[i*temp+j][0] == 'hist':\n",
    "                            ax[i, j].hist(self.DataHandler.df[plot_list[i*temp+j][1]], bins=10)\n",
    "                        # plotting box plot\n",
    "                        elif plot_list[i*temp+j][0] == 'box':\n",
    "                            ax[i, j].boxplot(self.DataHandler.df[plot_list[i*temp+j][1]])\n",
    "                        # plotting violin plot\n",
    "                        elif plot_list[i*temp+j][0] == 'violin':\n",
    "                            ax[i, j].violinplot(self.DataHandler.df[plot_list[i*temp+j][1]])\n",
    "                        elif plot_list[i*temp+j][0] == 'bullet':\n",
    "                            ax[i, j].bullet(self.DataHandler.df[plot_list[i*temp+j][1]])\n",
    "                        elif plot_list[i*temp+j][0] == 'table':\n",
    "                            ax[i, j].table(self.DataHandler.df[plot_list[i*temp+j][1]])\n",
    "                        elif plot_list[i*temp+j][0] == 'sparkline':\n",
    "                            ax[i, j].sparkline(self.DataHandler.df[plot_list[i*temp+j][1]])\n",
    "                        elif plot_list[i*temp+j][0] == 'connected scatter plot':\n",
    "                            ax[i, j].connectedscatterplot(self.DataHandler.df[plot_list[i*temp+j][1]])\n",
    "                        elif plot_list[i*temp+j][0] == 'pie':\n",
    "                            ax[i, j].pie(self.DataHandler.df[plot_list[i*temp+j][1]])\n",
    "                        elif plot_list[i*temp+j][0] == 'doughnut':\n",
    "                            ax[i, j].doughnut(self.DataHandler.df[plot_list[i*temp+j][1]])\n",
    "                        elif plot_list[i*temp+j][0] == 'gauge':\n",
    "                            ax[i, j].gauge(self.DataHandler.df[plot_list[i*temp+j][1]])\n",
    "                        elif plot_list[i*temp+j][0] == 'waffle':\n",
    "                            ax[i, j].waffle(self.DataHandler.df[plot_list[i*temp+j][1]])\n",
    "                        # invalid plot type\n",
    "                        else:\n",
    "                            print_sys_msg('DataVisualization:create_base_plots: invalid plot type')\n",
    "                        ax[i, j].set_xlabel(plot_list[i*temp+j][1])\n",
    "                        ax[i, j].set_ylabel(plot_list[i*temp+j][2])\n",
    "                        ax[i, j].set_title(plot_list[i*temp+j][1]+' vs '+plot_list[i*temp+j][2])\n",
    "                                                                                        \n",
    "        plt.show()\n",
    "\n",
    "    #-----------------matplot based Base Data Visualization Functions-----------------#\n",
    "    \n",
    "    #-----------------seaborn based Base Data Visualization Functions-----------------#\n",
    "    \n",
    "    def sns_create_linear_sub_plots(self, arrangment ,plot_list):\n",
    "        print_sys_msg('DataVisualization:create_base_plots: creating base plots')\n",
    "        number_of_plots = len(plot_list)\n",
    "\n",
    "        if arrangment == 'left_to_right':\n",
    "            fig, ax = plt.subplots(1, number_of_plots, figsize=(20, 20))\n",
    "        elif arrangment == 'top_to_bottom':\n",
    "            fig, ax = plt.subplots(number_of_plots, 1, figsize=(20, 20))  \n",
    "        else:\n",
    "            print_sys_msg('DataVisualization:create_base_plots: invalid arrangement type') \n",
    "            return    \n",
    "        \n",
    "        for i in range(number_of_plots):\n",
    "            if len(plot_list[i]) >= 3:\n",
    "                # plotting line graph\n",
    "                if plot_list[i][0] == 'line':\n",
    "                    sns.lineplot(x=plot_list[i][1], y=plot_list[i][2], data=self.DataHandler.df, ax=ax[i])\n",
    "                # plotting scatter graph\n",
    "                elif plot_list[i][0] == 'scatter':\n",
    "                    sns.scatterplot(x=plot_list[i][1], y=plot_list[i][2], data=self.DataHandler.df, ax=ax[i])\n",
    "                # plotting bar graph\n",
    "                elif plot_list[i][0] == 'bar':\n",
    "                    sns.barplot(x=plot_list[i][1], y=plot_list[i][2], data=self.DataHandler.df, ax=ax[i])\n",
    "                # plotting histogram\n",
    "                elif plot_list[i][0] == 'hist':\n",
    "                    sns.histplot(x=plot_list[i][1], data=self.DataHandler.df, ax=ax[i])\n",
    "                # plotting box plot\n",
    "                elif plot_list[i][0] == 'box':\n",
    "                    sns.boxplot(x=plot_list[i][1], data=self.DataHandler.df, ax=ax[i])\n",
    "                # plotting violin plot\n",
    "                elif plot_list[i][0] == 'violin':\n",
    "                    sns.violinplot(x=plot_list[i][1], data=self.DataHandler.df, ax=ax[i])\n",
    "                elif plot_list[i][0] == 'bullet':\n",
    "                    sns.bullet(x=plot_list[i][1], data=self.DataHandler.df, ax=ax[i])\n",
    "                elif plot_list[i][0] == 'table':\n",
    "                    sns.table(x=plot_list[i][1], data=self.DataHandler.df, ax=ax[i])\n",
    "                elif plot_list[i][0] == 'sparkline':\n",
    "                    sns.sparkline(x=plot_list[i][1], data=self.DataHandler.df, ax=ax[i])\n",
    "                elif plot_list[i][0] == 'connected scatter plot':\n",
    "                    sns.connectedscatterplot(x=plot_list[i][1], data=self.DataHandler.df, ax=ax[i])\n",
    "                elif plot_list[i][0] == 'pie':\n",
    "                    sns.pie(x=plot_list[i][1], data=self.DataHandler.df, ax=ax[i])\n",
    "                elif plot_list[i][0] == 'doughnut':\n",
    "                    sns.doughnut(x=plot_list[i][1], data=self.DataHandler.df, ax=ax[i])\n",
    "                elif plot_list[i][0] == 'gauge':\n",
    "                    sns.gauge(x=plot_list[i][1], data=self.DataHandler.df, ax=ax[i])\n",
    "                elif plot_list[i][0] == 'waffle':\n",
    "                    sns.waffle(x=plot_list[i][1], data=self.DataHandler.df, ax=ax[i])\n",
    "                # invalid plot type\n",
    "                else:\n",
    "                    print_sys_msg('DataVisualization:create_base_plots: invalid plot type')\n",
    "                \n",
    "                ax[i].set_xlabel(plot_list[i][1])\n",
    "                ax[i].set_ylabel(plot_list[i][2])\n",
    "                ax[i].set_title(plot_list[i][1]+' vs '+plot_list[i][2])\n",
    "                                                                                \n",
    "        plt.show()\n",
    "    \n",
    "    def sns_create_grid_sub_plots(self, plot_list):\n",
    "        print_sys_msg('DataVisualization:create_base_plots: creating base plots')\n",
    "\n",
    "        number_of_plots = len(plot_list)\n",
    "        print_sys_msg('DataVisualization:create_base_plots: number_of_plots: '+str(number_of_plots))\n",
    "        temp = math.ceil(math.sqrt(number_of_plots))\n",
    "        print_sys_msg('DataVisualization:create_base_plots: temp: '+str(temp))\n",
    "        fig, ax = plt.subplots(temp, temp, figsize=(20, 20))\n",
    "\n",
    "        for i in range(temp):\n",
    "            for j in range(temp):\n",
    "                if (i*temp+j) < number_of_plots:\n",
    "                    if len(plot_list[i*temp+j]) >= 3:\n",
    "                        # plotting line graph\n",
    "                        if plot_list[i*temp+j][0] == 'line':\n",
    "                            sns.lineplot(x=plot_list[i*temp+j][1], y=plot_list[i*temp+j][2], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        # plotting scatter graph\n",
    "                        elif plot_list[i*temp+j][0] == 'scatter':\n",
    "                            sns.scatterplot(x=plot_list[i*temp+j][1], y=plot_list[i*temp+j][2], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        # plotting bar graph\n",
    "                        elif plot_list[i*temp+j][0] == 'bar':\n",
    "                            sns.barplot(x=plot_list[i*temp+j][1], y=plot_list[i*temp+j][2], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        # plotting histogram\n",
    "                        elif plot_list[i*temp+j][0] == 'hist':\n",
    "                            sns.histplot(x=plot_list[i*temp+j][1], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        # plotting box plot\n",
    "                        elif plot_list[i*temp+j][0] == 'box':\n",
    "                            sns.boxplot(x=plot_list[i*temp+j][1], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        # plotting violin plot\n",
    "                        elif plot_list[i*temp+j][0] == 'violin':\n",
    "                            sns.violinplot(x=plot_list[i*temp+j][1], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        elif plot_list[i*temp+j][0] == 'bullet':\n",
    "                            sns.bullet(x=plot_list[i*temp+j][1], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        elif plot_list[i*temp+j][0] == 'table':\n",
    "                            sns.table(x=plot_list[i*temp+j][1], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        elif plot_list[i*temp+j][0] == 'sparkline':\n",
    "                            sns.sparkline(x=plot_list[i*temp+j][1], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        elif plot_list[i*temp+j][0] == 'connected scatter plot':\n",
    "                            sns.connectedscatterplot(x=plot_list[i*temp+j][1], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        elif plot_list[i*temp+j][0] == 'pie':\n",
    "                            sns.pie(x=plot_list[i*temp+j][1], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        elif plot_list[i*temp+j][0] == 'doughnut':\n",
    "                            sns.doughnut(x=plot_list[i*temp+j][1], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        elif plot_list[i*temp+j][0] == 'gauge':\n",
    "                            sns.gauge(x=plot_list[i*temp+j][1], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        elif plot_list[i*temp+j][0] == 'waffle':\n",
    "                            sns.waffle(x=plot_list[i*temp+j][1], data=self.DataHandler.df, ax=ax[i, j])\n",
    "                        # invalid plot type\n",
    "                        else:\n",
    "                            print_sys_msg('DataVisualization:create_base_plots: invalid plot type')\n",
    "                        ax[i, j].set_xlabel(plot_list[i*temp+j][1])\n",
    "                        ax[i, j].set_ylabel(plot_list[i*temp+j][2])\n",
    "                        ax[i, j].set_title(plot_list[i*temp+j][1]+' vs '+plot_list[i*temp+j][2])\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Initiation Phase  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import  \n",
    "importing 3 seperate files containing the data from phyphox of each member of the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataHandler()\n",
    "data.import_data(['data/member1.csv', 'data/member2.csv', 'data/member3.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the shape of the dataframe\n",
    "data.data_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first 5 rows of the dataframe\n",
    "data.data_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the information of the dataframe\n",
    "data.data_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the description of the dataframe\n",
    "data.data_describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the null values in the dataframe\n",
    "data.data_null()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the correlation matrix of the dataframe\n",
    "data.data_corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print duplicates in the data\n",
    "data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null values\n",
    "data.drop_null()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop negative time values\n",
    "data.drop_negative_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Managing missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop missing values\n",
    "# data.drop_missing()\n",
    "\n",
    "# # fill missing values with mean of the column \n",
    "# data.fill_missing()\n",
    "\n",
    "# # fill missing values with median of the column\n",
    "# data.fill_missing_median()\n",
    "\n",
    "# # fill missing values with mode of the column\n",
    "# data.fill_missing_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # min-max normalization\n",
    "# data.min_max_normalization()\n",
    "\n",
    "# # standardization\n",
    "# data.standardization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization before Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DataVisualization(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting left to right flowing subplots with line, scatter, and bar graphs. Matplotlib based.\n",
    "dv.plt_create_linear_sub_plots('left_to_right',[['line', 'Time (s)', 'Absolute acceleration (m/s^2)'], ['scatter', 'Time (s)', 'Absolute acceleration (m/s^2)'], ['bar', 'Time (s)', 'Absolute acceleration (m/s^2)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting grid subplots with line, scatter, and bar graphs. Matplotlib based.\n",
    "dv.plt_create_grid_sub_plots([['bar', 'Time (s)', 'Absolute acceleration (m/s^2)'], ['box', 'Time (s)', 'Absolute acceleration (m/s^2)'], ['bar', 'Time (s)', 'Absolute acceleration (m/s^2)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting left to right flowing subplots with line, scatter, and bar graphs. Seaborn based.\n",
    "dv.sns_create_linear_sub_plots('left_to_right',[['line', 'Time (s)', 'Absolute acceleration (m/s^2)'], ['bar', 'Time (s)', 'Absolute acceleration (m/s^2)'], ['bar', 'Time (s)', 'Absolute acceleration (m/s^2)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting grid subplots with line, scatter, and bar graphs. Seaborn based.\n",
    "dv.sns_create_grid_sub_plots([['line', 'Time (s)', 'Absolute acceleration (m/s^2)'], ['scatter', 'Time (s)', 'Absolute acceleration (m/s^2)'], ['bar', 'Time (s)', 'Absolute acceleration (m/s^2)']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Data after processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the data to a csv file\n",
    "data.store_data_with_name('data/cleaned_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
